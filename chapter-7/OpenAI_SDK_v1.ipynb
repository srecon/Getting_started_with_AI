{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e576bc4-2cce-4211-a22f-14ee87c6562f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai-agents in /opt/miniconda3/envs/ai-env/lib/python3.11/site-packages (0.0.6)\n",
      "Requirement already satisfied: duckduckgo-search in /opt/miniconda3/envs/ai-env/lib/python3.11/site-packages (7.5.2)\n",
      "Requirement already satisfied: griffe<2,>=1.5.6 in /opt/miniconda3/envs/ai-env/lib/python3.11/site-packages (from openai-agents) (1.6.1)\n",
      "Requirement already satisfied: openai>=1.66.5 in /opt/miniconda3/envs/ai-env/lib/python3.11/site-packages (from openai-agents) (1.66.5)\n",
      "Requirement already satisfied: pydantic<3,>=2.10 in /opt/miniconda3/envs/ai-env/lib/python3.11/site-packages (from openai-agents) (2.10.6)\n",
      "Requirement already satisfied: requests<3,>=2.0 in /opt/miniconda3/envs/ai-env/lib/python3.11/site-packages (from openai-agents) (2.32.3)\n",
      "Requirement already satisfied: types-requests<3,>=2.0 in /opt/miniconda3/envs/ai-env/lib/python3.11/site-packages (from openai-agents) (2.32.0.20250306)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.12.2 in /opt/miniconda3/envs/ai-env/lib/python3.11/site-packages (from openai-agents) (4.12.2)\n",
      "Requirement already satisfied: click>=8.1.8 in /opt/miniconda3/envs/ai-env/lib/python3.11/site-packages (from duckduckgo-search) (8.1.8)\n",
      "Requirement already satisfied: primp>=0.14.0 in /opt/miniconda3/envs/ai-env/lib/python3.11/site-packages (from duckduckgo-search) (0.14.0)\n",
      "Requirement already satisfied: lxml>=5.3.0 in /opt/miniconda3/envs/ai-env/lib/python3.11/site-packages (from duckduckgo-search) (5.3.1)\n",
      "Requirement already satisfied: colorama>=0.4 in /opt/miniconda3/envs/ai-env/lib/python3.11/site-packages (from griffe<2,>=1.5.6->openai-agents) (0.4.6)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/miniconda3/envs/ai-env/lib/python3.11/site-packages (from openai>=1.66.5->openai-agents) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/miniconda3/envs/ai-env/lib/python3.11/site-packages (from openai>=1.66.5->openai-agents) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/miniconda3/envs/ai-env/lib/python3.11/site-packages (from openai>=1.66.5->openai-agents) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/miniconda3/envs/ai-env/lib/python3.11/site-packages (from openai>=1.66.5->openai-agents) (0.8.2)\n",
      "Requirement already satisfied: sniffio in /opt/miniconda3/envs/ai-env/lib/python3.11/site-packages (from openai>=1.66.5->openai-agents) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /opt/miniconda3/envs/ai-env/lib/python3.11/site-packages (from openai>=1.66.5->openai-agents) (4.67.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/miniconda3/envs/ai-env/lib/python3.11/site-packages (from pydantic<3,>=2.10->openai-agents) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/miniconda3/envs/ai-env/lib/python3.11/site-packages (from pydantic<3,>=2.10->openai-agents) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/miniconda3/envs/ai-env/lib/python3.11/site-packages (from requests<3,>=2.0->openai-agents) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/envs/ai-env/lib/python3.11/site-packages (from requests<3,>=2.0->openai-agents) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/envs/ai-env/lib/python3.11/site-packages (from requests<3,>=2.0->openai-agents) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/envs/ai-env/lib/python3.11/site-packages (from requests<3,>=2.0->openai-agents) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/miniconda3/envs/ai-env/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai>=1.66.5->openai-agents) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/miniconda3/envs/ai-env/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.66.5->openai-agents) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U openai-agents duckduckgo-search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83dcc82d-ff86-4b19-af55-47fe43c9f5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Agent, Runner, OpenAIChatCompletionsModel, AsyncOpenAI, OpenAIChatCompletionsModel, function_tool, trace\n",
    "from duckduckgo_search import DDGS\n",
    "#from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1635f5e8-91b7-4c35-9408-d9dd4a8ccde5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nest-asyncio in /opt/miniconda3/envs/ai-env/lib/python3.11/site-packages (1.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install nest-asyncio\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae991bdb-0689-4a8c-a0cb-401423428061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, here's a light one for you: Why don't scientists trust atoms?\n",
      "\n",
      "Because they make up everything!\n"
     ]
    }
   ],
   "source": [
    "# Configure the model\n",
    "model = OpenAIChatCompletionsModel( \n",
    "    model=\"qwen2.5:7b\",\n",
    "    openai_client=AsyncOpenAI(base_url=\"http://localhost:11434/v1\")\n",
    ")\n",
    "\n",
    "# check the connection, a simple agent for interacting with local LLM\n",
    "agent = Agent(\n",
    "    name=\"Chatbot\",\n",
    "    instructions=\"You are a local chatbot\",\n",
    "    model=model\n",
    ")\n",
    "\n",
    "result = Runner.run_sync(agent, \"Tell me a joke.\")\n",
    "\n",
    "print(result.final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3a6c313-6bca-4a7a-b0b0-087d4f7dcb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_tool\n",
    "def get_news_articles(topic):\n",
    "    print(f\"Running DuckDuckGo news search for {topic}...\")\n",
    "    \n",
    "    # DuckDuckGo search\n",
    "    ddg_api = DDGS()\n",
    "    results = ddg_api.text(f\"{topic} \", max_results=5)\n",
    "    if results:\n",
    "        news_results = \"\\n\\n\".join([f\"Title: {result['title']}\\nURL: {result['href']}\\nDescription: {result['body']}\" for result in results])\n",
    "        print(news_results)\n",
    "        return news_results\n",
    "    else:\n",
    "        return f\"Could not find news results for {topic}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "159f14bc-c6b2-4fb3-b570-987982fa1117",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_planner_agent = Agent(\n",
    "    name=\"Content Planner\",\n",
    "    instructions=\"You are tasked with planning an engaging and informative blog post on {topic}. Your goal is to gather accurate, up-to-date information and structure the content\",\n",
    "    tools=[get_news_articles],\n",
    "    model=model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba69b77f-92be-437c-9387-aa4015ddc342",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer_agent = Agent(\n",
    "    name=\"Technical content writer\",\n",
    "    instructions=\"You are the technical content writer assigned to create a detailed and factually accurate blog post on: {topic}\",\n",
    "    model=model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30f18f8c-e0b4-4e99-a1b1-44a8da5bddef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent workflow\n",
    "def openai_agent_workflow(topic):\n",
    "    print(\"Running Agent workflow...\")\n",
    "\n",
    "    # Step 1: Search and fetch articles by the content_planner_agent agent\n",
    "    content_planner_response = Runner.run_sync(\n",
    "        content_planner_agent,\n",
    "        f\"Get me the articles about {topic} \"\n",
    "    )\n",
    "    \n",
    "    # Access the content from Run Result object\n",
    "    raw_articles = content_planner_response.final_output\n",
    "    \n",
    "    # Step 2: Pass articles to editor for final review\n",
    "    edited_news_response = Runner.run_sync(\n",
    "        writer_agent,\n",
    "        raw_articles\n",
    "    )\n",
    "    \n",
    "    # Access the content from RunResult object\n",
    "    edited_article = edited_news_response.final_output\n",
    "    \n",
    "    print(\"Final article:\")\n",
    "    print(edited_article)\n",
    "    \n",
    "    return edited_article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31dc3388-9f1f-47a8-8d26-df465842d08f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Agent workflow...\n",
      "Running DuckDuckGo news search for Step by step example of installing Apache Ignite v3 on Docker...\n",
      "Title: Installing Using Docker | Ignite Documentation - Apache Ignite\n",
      "URL: https://ignite.apache.org/docs/latest/installation/installing-using-docker\n",
      "Description: By default, Ignite Docker image exposes the following ports: 11211, 47100, 47500, 49112. You can expose more ports as needed by adding -p  to the docker run command. For example, to connect a thin client to the node running inside a docker container, open port 10800:\n",
      "\n",
      "Title: Apache Ignite: Setup Guide - DZone\n",
      "URL: https://dzone.com/articles/apache-ignite-setup-guide\n",
      "Description: Learn steps for binary installation, steps for building from sources, and steps for Maven to set up Apache Ignite. ... sources, Docker or cloud images, and Maven. There is also third-party support ...\n",
      "\n",
      "Title: Getting started with Apache Ignite - installation and setup\n",
      "URL: https://the-pi-guy.com/blog/getting_started_with_apache_ignite__installation_and_setup/\n",
      "Description: In this post, we'll cover the installation and setup process for Apache Ignite. Step 1: Install Apache Ignite # First, we need to download the Apache Ignite binary from the official website. Let's assume we've downloaded the binary to our local machine. We can install it using the following command:./ignite.sh install. This will install Apache ...\n",
      "\n",
      "Title: Install or Setup Apache Ignite in Windows Step by Step Tutorial\n",
      "URL: https://iteritory.com/install-or-setup-apache-ignite-in-windows-step-by-step-tutorial/\n",
      "Description: In this tutorial, we will go over step by step to install Apache Ignite in standalone windows system. We'll cover the Linux installation in the subsequent blog. If you have any question/clarification regarding this blog post, feel free to use the comment box below. ... As part of this tutorial, I will install Apache ignite in my personal ...\n",
      "\n",
      "Title: Installing Using DEP and RPM Package | Ignite Documentation\n",
      "URL: https://ignite.apache.org/docs/latest/installation/deb-rpm\n",
      "Description: If running on Windows 10 WSL or Docker, you should start Apache Ignite as a stand-alone process (not as a service). To start an Ignite node with a custom configuration, run the following command: sudo systemctl start apache-ignite@\n",
      "Final article:\n",
      "### How to Install Apache Ignite v3 on Docker: A Comprehensive Guide\n",
      "\n",
      "Apache Ignite is an in-memory computing platform for enterprise-level applications. This blog post will guide you through the process of installing Apache Ignite version 3 using Docker. We'll cover the necessary steps and configurations to get your Apache Ignite cluster up and running.\n",
      "\n",
      "#### Step-by-Step Installation Guide Using Docker\n",
      "\n",
      "1. **Ensure Docker is Installed**\n",
      "   Before proceeding, make sure Docker is installed on your machine. You can download Docker from the [official website](https://www.docker.com/).\n",
      "\n",
      "2. **Pull the Apache Ignite Docker Image**\n",
      "   Open a terminal and run the following command to pull the latest version of the Apache Ignite Docker image:\n",
      "   ```sh\n",
      "   docker pull apacheignite/ignite\n",
      "   ```\n",
      "\n",
      "3. **Run the Apache Ignite Container**\n",
      "   You can start an Apache Ignite node in a Docker container with various configurations. Here’s an example command:\n",
      "   ```sh\n",
      "   docker run -p 10800:10800 -d --name ignite-node apacheignite/ignite\n",
      "   ```\n",
      "\n",
      "   In this command, `-p 10800:10800` maps port `10800` on the host to port `10800` inside the container. This allows you to connect a thin client to the node running inside the Docker container. You can adjust other ports as needed:\n",
      "   ```sh\n",
      "   docker run -p 11211:11211 -p 47500-47600:47500-47600 -d --name ignite-node apacheignite/ignite\n",
      "   ```\n",
      "\n",
      "   This command maps ports 11211 and a range from `47500` to `47600`. The default port mappings are as follows:\n",
      "   - **11211**: Ignite SQL thin client\n",
      "   - **47500-47600**: Server-to-server communication\n",
      "\n",
      "4. **Verify the Container Status**\n",
      "   Check if the Apache Ignite node is running correctly with the following command:\n",
      "   ```sh\n",
      "   docker ps\n",
      "   ```\n",
      "\n",
      "   You should see the `ignite-node` container listed, indicating that it’s operational.\n",
      "\n",
      "5. **Connecting a Thin Client to the Node**\n",
      "   To connect a thin client (e.g., JCache or SQL Cache) to the Apache Ignite node running in Docker, you can use the following command:\n",
      "   ```sh\n",
      "   wget https://ignite.apache.org/download-file/bin/3.0.0/apache-ignite-3.0.0-bin.zip\n",
      "   unzip apache-ignite-3.0.0-bin.zip\n",
      "   cd apache-ignite-3.0.0\n",
      "   ./bin/ignite.sh -s -H 127.0.0.1 -port 10800\n",
      "   ```\n",
      "\n",
      "   The `-s` flag starts the thin client in silent mode (no GUI), and the `-H` parameter specifies the host IP address of the Ignite node, and `10800` is the client port.\n",
      "\n",
      "6. **Scaling the Cluster**\n",
      "   You can scale your cluster by running more containers using similar commands:\n",
      "   ```sh\n",
      "   docker run -p 10801:10800 -d --name ignite-node-2 apacheignite/ignite\n",
      "   ```\n",
      "\n",
      "   Now, you have two nodes in your Ignite cluster, each running on different ports.\n",
      "\n",
      "7. **Managing Services (Optional)**\n",
      "   For better management and monitoring of Docker services, you can use tools like `docker-compose`. Create a `docker-compose.yml` file with the following content:\n",
      "   ```yaml\n",
      "   version: '3'\n",
      "   services:\n",
      "     ignite-node-1:\n",
      "       image: apacheignite/ignite\n",
      "       ports:\n",
      "         - \"10800:10800\"\n",
      "         - \"47500-47600:47500-47600\"\n",
      "       container_name: ignite-node-1\n",
      "     ignite-node-2:\n",
      "       image: apacheignite/ignite\n",
      "       ports:\n",
      "         - \"10801:10800\"\n",
      "         - \"47601-47700:47501-47600\"\n",
      "       container_name: ignite-node-2\n",
      "   ```\n",
      "\n",
      "   Then, start the services with:\n",
      "   ```sh\n",
      "   docker-compose up\n",
      "   ```\n",
      "\n",
      "#### Conclusion\n",
      "\n",
      "With these steps, you have successfully installed and configured Apache Ignite v3 using Docker. You can expand your cluster by adding more nodes as needed, manage them effectively via `docker-compose`, or manually through commands.\n",
      "\n",
      "For advanced configurations and further customization, refer to the official [Apache Ignite documentation](https://ignite.apache.org/docs/latest) and additional resources like the articles mentioned in this guide.\n",
      "### How to Install Apache Ignite v3 on Docker: A Comprehensive Guide\n",
      "\n",
      "Apache Ignite is an in-memory computing platform for enterprise-level applications. This blog post will guide you through the process of installing Apache Ignite version 3 using Docker. We'll cover the necessary steps and configurations to get your Apache Ignite cluster up and running.\n",
      "\n",
      "#### Step-by-Step Installation Guide Using Docker\n",
      "\n",
      "1. **Ensure Docker is Installed**\n",
      "   Before proceeding, make sure Docker is installed on your machine. You can download Docker from the [official website](https://www.docker.com/).\n",
      "\n",
      "2. **Pull the Apache Ignite Docker Image**\n",
      "   Open a terminal and run the following command to pull the latest version of the Apache Ignite Docker image:\n",
      "   ```sh\n",
      "   docker pull apacheignite/ignite\n",
      "   ```\n",
      "\n",
      "3. **Run the Apache Ignite Container**\n",
      "   You can start an Apache Ignite node in a Docker container with various configurations. Here’s an example command:\n",
      "   ```sh\n",
      "   docker run -p 10800:10800 -d --name ignite-node apacheignite/ignite\n",
      "   ```\n",
      "\n",
      "   In this command, `-p 10800:10800` maps port `10800` on the host to port `10800` inside the container. This allows you to connect a thin client to the node running inside the Docker container. You can adjust other ports as needed:\n",
      "   ```sh\n",
      "   docker run -p 11211:11211 -p 47500-47600:47500-47600 -d --name ignite-node apacheignite/ignite\n",
      "   ```\n",
      "\n",
      "   This command maps ports 11211 and a range from `47500` to `47600`. The default port mappings are as follows:\n",
      "   - **11211**: Ignite SQL thin client\n",
      "   - **47500-47600**: Server-to-server communication\n",
      "\n",
      "4. **Verify the Container Status**\n",
      "   Check if the Apache Ignite node is running correctly with the following command:\n",
      "   ```sh\n",
      "   docker ps\n",
      "   ```\n",
      "\n",
      "   You should see the `ignite-node` container listed, indicating that it’s operational.\n",
      "\n",
      "5. **Connecting a Thin Client to the Node**\n",
      "   To connect a thin client (e.g., JCache or SQL Cache) to the Apache Ignite node running in Docker, you can use the following command:\n",
      "   ```sh\n",
      "   wget https://ignite.apache.org/download-file/bin/3.0.0/apache-ignite-3.0.0-bin.zip\n",
      "   unzip apache-ignite-3.0.0-bin.zip\n",
      "   cd apache-ignite-3.0.0\n",
      "   ./bin/ignite.sh -s -H 127.0.0.1 -port 10800\n",
      "   ```\n",
      "\n",
      "   The `-s` flag starts the thin client in silent mode (no GUI), and the `-H` parameter specifies the host IP address of the Ignite node, and `10800` is the client port.\n",
      "\n",
      "6. **Scaling the Cluster**\n",
      "   You can scale your cluster by running more containers using similar commands:\n",
      "   ```sh\n",
      "   docker run -p 10801:10800 -d --name ignite-node-2 apacheignite/ignite\n",
      "   ```\n",
      "\n",
      "   Now, you have two nodes in your Ignite cluster, each running on different ports.\n",
      "\n",
      "7. **Managing Services (Optional)**\n",
      "   For better management and monitoring of Docker services, you can use tools like `docker-compose`. Create a `docker-compose.yml` file with the following content:\n",
      "   ```yaml\n",
      "   version: '3'\n",
      "   services:\n",
      "     ignite-node-1:\n",
      "       image: apacheignite/ignite\n",
      "       ports:\n",
      "         - \"10800:10800\"\n",
      "         - \"47500-47600:47500-47600\"\n",
      "       container_name: ignite-node-1\n",
      "     ignite-node-2:\n",
      "       image: apacheignite/ignite\n",
      "       ports:\n",
      "         - \"10801:10800\"\n",
      "         - \"47601-47700:47501-47600\"\n",
      "       container_name: ignite-node-2\n",
      "   ```\n",
      "\n",
      "   Then, start the services with:\n",
      "   ```sh\n",
      "   docker-compose up\n",
      "   ```\n",
      "\n",
      "#### Conclusion\n",
      "\n",
      "With these steps, you have successfully installed and configured Apache Ignite v3 using Docker. You can expand your cluster by adding more nodes as needed, manage them effectively via `docker-compose`, or manually through commands.\n",
      "\n",
      "For advanced configurations and further customization, refer to the official [Apache Ignite documentation](https://ignite.apache.org/docs/latest) and additional resources like the articles mentioned in this guide.\n"
     ]
    }
   ],
   "source": [
    "topic = \"Step by step example of installing Apache Ignite v3 on Docker.\"\n",
    "\n",
    "print(openai_agent_workflow(topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d45f8a2-f778-450c-8f05-5f7ad25179c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An editor agent for grammar and tone improvements.\n",
    "editor_agent = Agent(\n",
    "    name=\"Editor Agent\",\n",
    "    instructions=\"Proofread the given blog post for grammatical errors and alignment with human language for better readability while maintaining its original meaning.\",\n",
    "    handoffs=[content_planner_agent, writer_agent]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3731f668-6df0-46bb-8a62-5278df2eeb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent orchestration\n",
    "async def main():\n",
    "    result = await Runner.run(editor_agent, topic)\n",
    "    print(result.final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3a8eb4-fd27-4da9-a9ce-693b2f344b7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9c41ea-1cad-452f-b47c-9961a4af4c23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
